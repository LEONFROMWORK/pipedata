#!/usr/bin/env python3
"""
ì˜¤ë¹ ë‘ ì‹¤ì œ HTML êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
í˜„ì¬ í¬ë¡¤ëŸ¬ê°€ ì˜ëª»ëœ CSS ì„ íƒìë¥¼ ì‚¬ìš©í•˜ëŠ” ë¬¸ì œ í•´ê²°
"""

import requests
import cloudscraper
from bs4 import BeautifulSoup
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def analyze_oppadu_structure():
    """ì˜¤ë¹ ë‘ ì‹¤ì œ HTML êµ¬ì¡° ë¶„ì„"""
    
    url = "https://www.oppadu.com/community/question/"
    
    # CloudScraper ì‚¬ìš© (Cloudflare ìš°íšŒ)
    scraper = cloudscraper.create_scraper(
        browser={
            'browser': 'chrome',
            'platform': 'windows',
            'desktop': True
        }
    )
    
    # í•œêµ­ ì‚¬ìš©ì í—¤ë” ì„¤ì •
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Referer': 'https://www.oppadu.com/'
    }
    scraper.headers.update(headers)
    
    try:
        print(f"ğŸ” ì˜¤ë¹ ë‘ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„: {url}")
        response = scraper.get(url, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        print("\n" + "="*80)
        print("ğŸ“‹ ACTUAL HTML STRUCTURE ANALYSIS")
        print("="*80)
        
        # 1. í˜ì´ì§€ ì œëª© í™•ì¸
        title = soup.find('title')
        print(f"ğŸ“– Page Title: {title.get_text() if title else 'Not found'}")
        
        # 2. ì£¼ìš” ì»¨í…Œì´ë„ˆ ì°¾ê¸°
        print("\nğŸ” MAIN CONTAINERS:")
        containers = [
            'post-list-modern',  # í˜„ì¬ ì‚¬ìš©í•˜ëŠ” ì˜ëª»ëœ ì„ íƒì
            'post-item-modern',  # í˜„ì¬ ì‚¬ìš©í•˜ëŠ” ì˜ëª»ëœ ì„ íƒì
            'post-list',
            'post-item',
            'question-list',
            'board-list',
            'list-container',
            'content-list'
        ]
        
        for container in containers:
            elements = soup.find_all(class_=container)
            print(f"  .{container}: {len(elements)} elements found")
            if elements:
                print(f"    First element: {str(elements[0])[:200]}...")
        
        # 3. ê²Œì‹œê¸€ ë§í¬ íŒ¨í„´ ë¶„ì„
        print("\nğŸ”— POST URL PATTERNS:")
        all_links = soup.find_all('a', href=True)
        post_links = []
        
        for link in all_links:
            href = link['href']
            # ê²Œì‹œê¸€ URL íŒ¨í„´ ì°¾ê¸°
            if any(pattern in href for pattern in ['uid=', 'view', 'question', 'post']):
                post_links.append(href)
        
        print(f"  Total links found: {len(all_links)}")
        print(f"  Potential post links: {len(post_links)}")
        
        if post_links:
            print("  Sample post URLs:")
            for i, link in enumerate(post_links[:5]):
                print(f"    {i+1}. {link}")
        
        # 4. ë‹µë³€ ì™„ë£Œ í‘œì‹œ ì°¾ê¸°
        print("\nâœ… ANSWER COMPLETION INDICATORS:")
        completion_indicators = [
            'ë‹µë³€ì™„ë£Œ',
            'ë‹µë³€ ì™„ë£Œ',
            'í•´ê²°ì™„ë£Œ',
            'í•´ê²° ì™„ë£Œ',
            'answered',
            'completed',
            'solved'
        ]
        
        for indicator in completion_indicators:
            elements = soup.find_all(string=lambda text: text and indicator in text)
            print(f"  '{indicator}': {len(elements)} occurrences")
            if elements:
                for elem in elements[:2]:
                    parent = elem.parent
                    print(f"    Parent tag: {parent.name if parent else 'None'}")
                    print(f"    Parent class: {parent.get('class') if parent else 'None'}")
        
        # 5. ì‹¤ì œ ê²Œì‹œê¸€ êµ¬ì¡° ë¶„ì„
        print("\nğŸ“ POST STRUCTURE ANALYSIS:")
        
        # ì¼ë°˜ì ì¸ ê²Œì‹œíŒ êµ¬ì¡° íƒœê·¸ë“¤ í™•ì¸
        structure_tags = ['table', 'tr', 'td', 'ul', 'li', 'div']
        for tag in structure_tags:
            elements = soup.find_all(tag)
            if elements:
                # ê²Œì‹œê¸€ê³¼ ê´€ë ¨ëœ ê²ƒë“¤ë§Œ í•„í„°ë§
                relevant_elements = []
                for elem in elements:
                    classes = elem.get('class', [])
                    if any(keyword in ' '.join(classes).lower() for keyword in ['post', 'item', 'list', 'board', 'question']):
                        relevant_elements.append(elem)
                
                if relevant_elements:
                    print(f"  <{tag}> with post-related classes: {len(relevant_elements)}")
                    for elem in relevant_elements[:3]:
                        print(f"    Classes: {elem.get('class', [])}")
        
        # 6. ì‹¤ì œ HTML ìƒ˜í”Œ ì¶œë ¥
        print("\nğŸ”§ RAW HTML SAMPLE (first 2000 chars):")
        print("-" * 50)
        print(response.text[:2000])
        print("-" * 50)
        
        # 7. ìë°”ìŠ¤í¬ë¦½íŠ¸ë¡œ ë¡œë“œë˜ëŠ” ë‚´ìš©ì¸ì§€ í™•ì¸
        print("\nâš¡ JAVASCRIPT CONTENT CHECK:")
        script_tags = soup.find_all('script')
        js_content_indicators = ['ajax', 'fetch', 'xhr', 'api', 'json']
        
        js_found = False
        for script in script_tags:
            script_text = script.get_text()
            for indicator in js_content_indicators:
                if indicator in script_text.lower():
                    js_found = True
                    print(f"  JavaScript loading detected: '{indicator}' found in script")
                    break
        
        if not js_found:
            print("  No obvious JavaScript content loading detected")
        
        # 8. ê¶Œì¥ ìˆ˜ì •ì‚¬í•­ ì œì‹œ
        print("\nğŸ’¡ RECOMMENDED FIXES:")
        print("  Based on the analysis, the crawler should be updated to:")
        print("  1. Use correct CSS selectors for actual HTML structure")
        print("  2. Handle any JavaScript-rendered content if needed")
        print("  3. Update URL extraction logic for proper post links")
        print("  4. Fix answer completion detection logic")
        
        return response.text
        
    except Exception as e:
        print(f"âŒ Error analyzing structure: {e}")
        return None

if __name__ == "__main__":
    analyze_oppadu_structure()