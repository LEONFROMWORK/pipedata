#!/usr/bin/env python3
"""
ì‹¤ì œ tesseractì™€ í•¨ê»˜ ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (OpenRouter ì—†ì´ OCR/í…Œì´ë¸”ë§Œ)
"""
import asyncio
import json
import logging
import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from processors.image_processor import ImageProcessor
from core.cache import APICache, LocalCache

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

class MockImageProcessor(ImageProcessor):
    """ImageProcessor with OpenRouter disabled for testing OCR/table only"""
    
    def _should_use_ai_enhancement(self, ocr_result, table_result, context_tags):
        """Always return False to skip AI enhancement for testing"""
        return False

async def test_real_image_processing():
    """ì‹¤ì œ tesseractì™€ img2tableë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    
    # Initialize cache and processor
    local_cache = LocalCache(db_path=Path("/tmp/real_image_test_cache.db"))
    cache = APICache(local_cache)
    processor = MockImageProcessor(cache)
    
    # ì‹¤ì œ ìŠ¤íƒì˜¤ë²„í”Œë¡œìš° ì´ë¯¸ì§€ URLs (403 ìš°íšŒ ê²€ì¦ëœ)
    test_images = [
        {
            "url": "https://i.sstatic.net/AJr6APk8.png",
            "description": "Excel ë³µì¡í•œ ê³µì‹ ê²°ê³¼ ìŠ¤í¬ë¦°ìƒ·",
            "expected_type": "formula_result"
        },
        {
            "url": "https://i.sstatic.net/TpgieF6J.png", 
            "description": "Excel íŒŒìŠ¤ì¹¼ ì‚¼ê°í˜• ë°°ì—´ ê³µì‹",
            "expected_type": "table_data"
        },
        {
            "url": "https://i.sstatic.net/82NP1kgT.png",
            "description": "Excel í•„í„° ê³µì‹ ê²°ê³¼",
            "expected_type": "filtered_data"
        }
    ]
    
    logger.info("ğŸ”¬ ì‹¤ì œ tesseract OCR + img2table í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 70)
    
    processed_results = []
    
    for i, test_image in enumerate(test_images, 1):
        logger.info(f"[{i}/{len(test_images)}] ì²˜ë¦¬ ì¤‘: {test_image['description']}")
        logger.info(f"URL: {test_image['url']}")
        
        try:
            # Excel ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ íƒœê·¸
            context_tags = ["excel", "formula", "table", test_image["expected_type"]]
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤í–‰
            result = await processor.process_image_url(test_image["url"], context_tags)
            
            # ê²°ê³¼ ì €ì¥
            processed_result = {
                "test_info": {
                    "url": test_image["url"],
                    "description": test_image["description"],
                    "expected_type": test_image["expected_type"]
                },
                "processing_result": result
            }
            processed_results.append(processed_result)
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info("=" * 50)
            if result['success']:
                logger.info("âœ… ì²˜ë¦¬ ì„±ê³µ!")
                logger.info(f"   â€¢ ì²˜ë¦¬ ë‹¨ê³„: {result.get('processing_steps', [])}")
                logger.info(f"   â€¢ ì²˜ë¦¬ í‹°ì–´: {result.get('processing_tier', 'Unknown')}")
                logger.info(f"   â€¢ ì½˜í…ì¸  íƒ€ì…: {result.get('extracted_content_type', 'None')}")
                logger.info(f"   â€¢ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result.get('extracted_content', ''))} ë¬¸ì")
                
                # ì¶”ì¶œëœ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì)
                content = result.get('extracted_content', '')
                if content:
                    preview = content[:200] + "..." if len(content) > 200 else content
                    logger.info(f"   â€¢ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {repr(preview)}")
                else:
                    logger.warning("   â€¢ ì¶”ì¶œëœ ë‚´ìš© ì—†ìŒ")
            else:
                logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            
            logger.info("=" * 50)
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
            processed_results.append({
                "test_info": test_image,
                "processing_result": {"success": False, "error": str(e)}
            })
    
    # ìµœì¢… ê²°ê³¼ JSON ìƒì„±
    final_result = {
        "test_metadata": {
            "test_name": "Real Image Processing with tesseract + img2table",
            "test_date": "2025-07-18",
            "total_images": len(test_images),
            "processing_pipeline": "Tier 1 (tesseract) + Tier 2 (img2table) only",
            "ai_enhancement": "disabled_for_testing"
        },
        "results": processed_results,
        "summary": {
            "total_processed": len(processed_results),
            "successful": sum(1 for r in processed_results if r["processing_result"].get("success", False)),
            "failed": sum(1 for r in processed_results if not r["processing_result"].get("success", False))
        }
    }
    
    # JSON ì¶œë ¥
    logger.info("\n" + "=" * 70)
    logger.info("ğŸ“‹ ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ JSON:")
    logger.info("=" * 70)
    print(json.dumps(final_result, indent=2, ensure_ascii=False))
    
    # íŒŒì¼ ì €ì¥
    output_path = "/Users/kevin/bigdata/data/output/real_image_processing_results.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(final_result, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    
    # ìš”ì•½ í†µê³„
    summary = final_result["summary"]
    success_rate = (summary["successful"] / summary["total_processed"]) * 100 if summary["total_processed"] > 0 else 0
    
    logger.info(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
    logger.info(f"   â€¢ ì´ ì²˜ë¦¬: {summary['total_processed']}ê°œ")
    logger.info(f"   â€¢ ì„±ê³µ: {summary['successful']}ê°œ")
    logger.info(f"   â€¢ ì‹¤íŒ¨: {summary['failed']}ê°œ")
    logger.info(f"   â€¢ ì„±ê³µë¥ : {success_rate:.1f}%")
    
    return final_result

if __name__ == "__main__":
    asyncio.run(test_real_image_processing())