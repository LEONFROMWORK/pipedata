#!/usr/bin/env python3
"""
ì‹¤ì œ ì´ë¯¸ì§€ í¬í•¨ ë°ì´í„° ìˆ˜ì§‘ ë° AI ë³€í™˜ í…ŒìŠ¤íŠ¸
"""
import asyncio
import json
import logging
import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from processors.image_processor import ImageProcessor
from core.cache import APICache, LocalCache
from config import Config

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

async def test_image_processing_pipeline():
    """ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìˆëŠ” Q&A ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    
    # Initialize cache and processor
    local_cache = LocalCache(db_path=Path("/tmp/image_test_cache.db"))
    cache = APICache(local_cache)
    processor = ImageProcessor(cache)
    
    # í˜„ì¬ ë°ì´í„°ì…‹ì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìˆëŠ” ë°ì´í„° (í™•ì¸ëœ ì´ë¯¸ì§€ URLë“¤)
    sample_qa_with_images = {
        "id": "excel_qa_test_image",
        "user_question": "Excel array formula that references previously calculated values within the array",
        "user_context": "I want to create Pascal's Triangle in Excel using array formulas...",
        "assistant_response": """
<p>The formula for Pascal's triangle is:</p>
<pre><code>=LET(N,5,REDUCE(SEQUENCE(,N,1,0),SEQUENCE(N-1),
    LAMBDA(y,z,VSTACK(y,SCAN(0,TAKE(y,-1),LAMBDA(a,x,a+x))))))
</code></pre>
<p><a href="https://i.sstatic.net/TpgieF6J.png" rel="nofollow noreferrer"><img src="https://i.sstatic.net/TpgieF6J.png" alt="enter image description here" /></a></p>
""",
        "image_urls": ["https://i.sstatic.net/TpgieF6J.png"],
        "metadata": {
            "difficulty": "advanced",
            "functions": ["LET", "LAMBDA", "REDUCE", "SEQUENCE"],
            "source": "stackoverflow"
        }
    }
    
    logger.info("ğŸ”„ ì‹¤ì œ ì´ë¯¸ì§€ í¬í•¨ Q&A ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    logger.info("=" * 60)
    
    # Process each image in the Q&A
    processed_images = []
    
    for image_url in sample_qa_with_images["image_urls"]:
        logger.info(f"ğŸ“¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {image_url}")
        
        try:
            # Excel ê´€ë ¨ íƒœê·¸ ì¶”ê°€ (AI ì²˜ë¦¬ íŒíŠ¸)
            context_tags = sample_qa_with_images["metadata"]["functions"] + ["excel", "formula"]
            
            # 3-tier ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            result = await processor.process_image_url(image_url, context_tags)
            
            processed_images.append({
                "original_url": image_url,
                "processing_result": result
            })
            
            # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
            if result['success']:
                logger.info(f"âœ… ì²˜ë¦¬ ì„±ê³µ:")
                logger.info(f"   â€¢ ì²˜ë¦¬ ë‹¨ê³„: {result['processing_tier']}")
                logger.info(f"   â€¢ ì½˜í…ì¸  íƒ€ì…: {result['extracted_content_type']}")
                logger.info(f"   â€¢ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result['extracted_content'])} ë¬¸ì")
                if result.get('ai_model_used'):
                    logger.info(f"   â€¢ ì‚¬ìš©ëœ AI ëª¨ë¸: {result['ai_model_used']}")
                    logger.info(f"   â€¢ í† í° ì‚¬ìš©ëŸ‰: {result.get('tokens_used', 0)}")
            else:
                logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            processed_images.append({
                "original_url": image_url,
                "processing_result": {"success": False, "error": str(e)}
            })
    
    # ìµœì¢… JSON í˜•ì‹ìœ¼ë¡œ ê²°í•©
    final_qa_with_processed_images = {
        "id": sample_qa_with_images["id"],
        "user_question": sample_qa_with_images["user_question"],
        "user_context": sample_qa_with_images["user_context"],
        "assistant_response": sample_qa_with_images["assistant_response"],
        "code_blocks": ["=LET(N,5,REDUCE(SEQUENCE(,N,1,0),SEQUENCE(N-1),", "    LAMBDA(y,z,VSTACK(y,SCAN(0,TAKE(y,-1),LAMBDA(a,x,a+x))))))"],
        "image_contexts": [],  # AIë¡œ ì¶”ì¶œëœ ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸
        "metadata": sample_qa_with_images["metadata"]
    }
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ë¥¼ image_contextsì— ì¶”ê°€
    for processed_image in processed_images:
        if processed_image["processing_result"]["success"]:
            image_context = {
                "source_url": processed_image["original_url"],
                "extracted_content": processed_image["processing_result"]["extracted_content"],
                "content_type": processed_image["processing_result"]["extracted_content_type"],
                "processing_method": processed_image["processing_result"]["processing_tier"],
                "ai_model": processed_image["processing_result"].get("ai_model_used"),
                "confidence": "high" if processed_image["processing_result"].get("ai_model_used") else "medium"
            }
            final_qa_with_processed_images["image_contexts"].append(image_context)
    
    logger.info("=" * 60)
    logger.info("ğŸ“‹ ìµœì¢… JSON ê²°ê³¼:")
    print(json.dumps(final_qa_with_processed_images, indent=2, ensure_ascii=False))
    
    # íŒŒì¼ë¡œë„ ì €ì¥
    output_path = "/Users/kevin/bigdata/data/output/sample_with_processed_images.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(final_qa_with_processed_images, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_path}")
    
    return final_qa_with_processed_images

if __name__ == "__main__":
    asyncio.run(test_image_processing_pipeline())