#!/usr/bin/env python3
"""
ë…ë¦½ Reddit ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
Reddit ì „ìš© ë…ë¦½ ì‹œìŠ¤í…œì˜ ì™„ì „í•œ í…ŒìŠ¤íŠ¸
"""
import asyncio
import sys
import os
import json
import logging
from datetime import datetime
from typing import Dict, Any, List
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '/Users/kevin/bigdata/new_system')

from collectors.reddit_system import RedditCollector
from shared.utils import save_jsonl, get_output_path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_reddit_system():
    """ë…ë¦½ Reddit ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ ë…ë¦½ Reddit ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    try:
        # Reddit ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        print("ğŸ“‹ Reddit ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”...")
        collector = RedditCollector()
        print("âœ… Reddit ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì„¤ì • ê²€ì¦
        print("\nğŸ” ì„¤ì • ê²€ì¦...")
        config = collector.config
        if not config.validate_config():
            print("âŒ Reddit ì„¤ì • ê²€ì¦ ì‹¤íŒ¨")
            return False
        print("âœ… Reddit ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        
        # ë…ë¦½ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        print("\nğŸ“Š ë…ë¦½ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸...")
        print(f"ìºì‹œ DB: {config.cache_db_path}")
        print(f"ì¤‘ë³µ ì¶”ì  DB: {config.dedup_db_path}")
        print(f"ì¶œë ¥ ê²½ë¡œ: {config.output_base_path}")
        
        # ìºì‹œ í†µê³„
        cache_stats = collector.cache.cache.get_stats()
        print(f"ìºì‹œ í†µê³„: {cache_stats}")
        
        # ì¤‘ë³µ ì¶”ì  í†µê³„
        dedup_stats = collector.dedup_tracker.get_reddit_stats()
        print(f"ì¤‘ë³µ ì¶”ì  í†µê³„: {dedup_stats}")
        
        # ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
        print("\nğŸš€ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...")
        start_time = datetime.now()
        
        # ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (5ê°œ í•­ëª©)
        collected_data = await collector.collect_excel_qa_data(max_items=5)
        
        end_time = datetime.now()
        collection_time = (end_time - start_time).total_seconds()
        
        print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ìˆ˜ì§‘ ì‹œê°„: {collection_time:.2f}ì´ˆ")
        print(f"ìˆ˜ì§‘ëœ í•­ëª©: {len(collected_data)}ê°œ")
        
        # ìˆ˜ì§‘ í†µê³„ ì¶œë ¥
        stats = collector.get_detailed_stats()
        print(f"\nğŸ“ˆ ìƒì„¸ í†µê³„:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦...")
        quality_issues = 0
        
        for i, entry in enumerate(collected_data, 1):
            print(f"\nğŸ“‹ í•­ëª© {i}:")
            print(f"  ID: {entry.id}")
            print(f"  ì§ˆë¬¸: {entry.user_question[:80]}...")
            print(f"  ë‹µë³€: {entry.assistant_response[:80]}...")
            print(f"  í’ˆì§ˆ ì ìˆ˜: {entry.metadata.get('quality_score', 0)}")
            print(f"  ì†ŒìŠ¤: {entry.metadata.get('source', 'unknown')}")
            print(f"  ë´‡ íƒì§€: {entry.metadata.get('bot_detection_version', 'none')}")
            
            # í’ˆì§ˆ ê²€ì¦
            if not entry.user_question.strip():
                quality_issues += 1
                print(f"    âš ï¸ ë¹ˆ ì§ˆë¬¸")
            
            if not entry.assistant_response.strip():
                quality_issues += 1
                print(f"    âš ï¸ ë¹ˆ ë‹µë³€")
            
            if entry.metadata.get('quality_score', 0) < 2.0:
                quality_issues += 1
                print(f"    âš ï¸ ë‚®ì€ í’ˆì§ˆ ì ìˆ˜")
        
        # ê²°ê³¼ ì €ì¥
        if collected_data:
            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥...")
            output_path = get_output_path(
                config.output_base_path,
                'reddit_independent_test'
            )
            
            # QAEntryë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            data_dicts = [entry.to_dict() for entry in collected_data]
            save_jsonl(data_dicts, output_path)
            
            print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                'test_timestamp': datetime.now().isoformat(),
                'system_type': 'independent_reddit',
                'total_collected': len(collected_data),
                'collection_time_seconds': collection_time,
                'quality_issues': quality_issues,
                'statistics': stats,
                'config_summary': {
                    'subreddits': config.subreddits,
                    'max_submissions_per_subreddit': config.max_submissions_per_subreddit,
                    'min_upvotes': config.min_upvotes,
                    'bot_detection_enabled': config.bot_detection_enabled
                }
            }
            
            metadata_path = output_path.with_suffix('.metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_path}")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‰ê°€
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‰ê°€:")
        
        success_rate = len(collected_data) / 5 * 100  # ëª©í‘œ 5ê°œ ëŒ€ë¹„
        print(f"ìˆ˜ì§‘ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        if quality_issues == 0:
            print("âœ… í’ˆì§ˆ ê²€ì¦: ëª¨ë“  í•­ëª©ì´ í’ˆì§ˆ ê¸°ì¤€ì„ ì¶©ì¡±")
        else:
            print(f"âš ï¸ í’ˆì§ˆ ê²€ì¦: {quality_issues}ê°œ í•­ëª©ì—ì„œ í’ˆì§ˆ ë¬¸ì œ ë°œê²¬")
        
        # ë…ë¦½ì„± ê²€ì¦
        print(f"\nğŸ”’ ë…ë¦½ì„± ê²€ì¦:")
        print(f"âœ… ë…ë¦½ ìºì‹œ DB: {config.cache_db_path}")
        print(f"âœ… ë…ë¦½ ì¤‘ë³µ ì¶”ì  DB: {config.dedup_db_path}")
        print(f"âœ… ë…ë¦½ ì„¤ì • í´ë˜ìŠ¤: RedditConfig")
        
        # ì „ì²´ í‰ê°€
        if len(collected_data) > 0 and quality_issues < len(collected_data) * 0.3:
            print(f"\nğŸ‰ ë…ë¦½ Reddit ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"âœ… ì‹œìŠ¤í…œì´ ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤")
            return True
        else:
            print(f"\nâŒ ë…ë¦½ Reddit ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            print(f"ìˆ˜ì§‘ ì„±ê³µë¥  ë˜ëŠ” í’ˆì§ˆì´ ê¸°ì¤€ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤")
            return False
    
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ¯ ë…ë¦½ Reddit ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    success = await test_reddit_system()
    
    if success:
        print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print(f"ğŸš€ ë…ë¦½ Reddit ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤")
    else:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print(f"âš ï¸ ì‹œìŠ¤í…œ ì„¤ì • ë˜ëŠ” êµ¬í˜„ì„ í™•ì¸í•´ì£¼ì„¸ìš”")

if __name__ == "__main__":
    asyncio.run(main())