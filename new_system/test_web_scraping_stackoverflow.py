#!/usr/bin/env python3
"""
ì›¹ ìŠ¤í¬ë˜í•‘ ê¸°ë°˜ Stack Overflow ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸
- s-pagination í´ë˜ìŠ¤ ê¸°ë°˜ í˜ì´ì§€ ìˆœíšŒ í…ŒìŠ¤íŠ¸
- API ë°©ì‹ê³¼ ì›¹ ìŠ¤í¬ë˜í•‘ ë°©ì‹ ë¹„êµ
"""
import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))

from config import Config
from core.cache import LocalCache, APICache
from collectors.web_scraping_stackoverflow import WebScrapingStackOverflowCollector

async def test_web_scraping_collector():
    """ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸŒ ì›¹ ìŠ¤í¬ë˜í•‘ ê¸°ë°˜ Stack Overflow ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    try:
        # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        local_cache = LocalCache(Config.DATABASE_PATH)
        api_cache = APICache(local_cache)
        web_collector = WebScrapingStackOverflowCollector(api_cache)
        
        print("âœ… ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸ¯ s-pagination í´ë˜ìŠ¤ ê¸°ë°˜ í˜ì´ì§€ ìˆœíšŒ í…ŒìŠ¤íŠ¸")
        
        # í…ŒìŠ¤íŠ¸ ìˆ˜ì§‘ (ì‘ì€ ê·œëª¨)
        print("\nğŸš€ ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ ì‹œì‘...")
        start_time = datetime.now()
        
        web_qa_pairs = await web_collector.collect_excel_questions_web(
            max_pages=3  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 3í˜ì´ì§€ë§Œ
        )
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\nâ±ï¸ ì›¹ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ)")
        print(f"ğŸ“Š ì›¹ ìŠ¤í¬ë˜í•‘ ê²°ê³¼: {len(web_qa_pairs)}ê°œ Q&A ìŒ")
        
        if not web_qa_pairs:
            print("âŒ ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            await web_collector.close()
            return
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        print(f"\nğŸ” ì›¹ ìŠ¤í¬ë˜í•‘ ë°ì´í„° ë¶„ì„:")
        
        complete_pairs = sum(1 for pair in web_qa_pairs if pair.get('answer'))
        print(f"   ì™„ì „í•œ Q&A ìŒ: {complete_pairs}/{len(web_qa_pairs)} ({complete_pairs/len(web_qa_pairs)*100:.1f}%)")
        
        # ì ìˆ˜ ë¶„ì„
        question_scores = [pair['question'].get('score', 0) for pair in web_qa_pairs]
        answer_scores = [pair['answer'].get('score', 0) for pair in web_qa_pairs if pair.get('answer')]
        quality_scores = [pair.get('quality_score', 0) for pair in web_qa_pairs]
        
        if question_scores:
            print(f"   ì§ˆë¬¸ ì ìˆ˜: {min(question_scores)} ~ {max(question_scores)} (í‰ê· : {sum(question_scores)/len(question_scores):.1f})")
        if answer_scores:
            print(f"   ë‹µë³€ ì ìˆ˜: {min(answer_scores)} ~ {max(answer_scores)} (í‰ê· : {sum(answer_scores)/len(answer_scores):.1f})")
        if quality_scores:
            print(f"   í’ˆì§ˆ ì ìˆ˜: {min(quality_scores)} ~ {max(quality_scores)} (í‰ê· : {sum(quality_scores)/len(quality_scores):.1f})")
        
        # ìƒ˜í”Œ Q&A ì¶œë ¥
        print(f"\nğŸ“ ì›¹ ìŠ¤í¬ë˜í•‘ ìƒ˜í”Œ Q&A:")
        for i, pair in enumerate(web_qa_pairs[:3], 1):
            question = pair['question']
            answer = pair.get('answer', {})
            
            print(f"\n   ìƒ˜í”Œ {i}:")
            print(f"   ğŸ“‹ ID: {question.get('question_id')}")
            print(f"   ğŸ“‹ ì œëª©: {question.get('title', 'N/A')[:80]}...")
            print(f"   ğŸ“‹ ì ìˆ˜: Q{question.get('score', 0)}/A{answer.get('score', 0)}")
            print(f"   ğŸ“‹ íƒœê·¸: {', '.join(question.get('tags', []))}")
            print(f"   ğŸ“‹ ì¡°íšŒìˆ˜: {question.get('view_count', 0):,}")
            print(f"   ğŸ’¬ ë‹µë³€ ì±„íƒ: {'Yes' if answer.get('is_accepted') else 'No'}")
            
            answer_preview = answer.get('body_markdown', '')[:200]
            print(f"   ğŸ’¬ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {answer_preview}...")
        
        # ë°ì´í„° ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        web_output_file = Path(Config.OUTPUT_DIR) / f"web_scraping_stackoverflow_{timestamp}.json"
        
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        save_data = []
        for pair in web_qa_pairs:
            save_item = {
                'question': pair['question'],
                'answer': pair.get('answer'),
                'quality_score': pair.get('quality_score', 0),
                'source': pair.get('source', 'web_scraping'),
                'collected_at': pair.get('collected_at')
            }
            save_data.append(save_item)
        
        with open(web_output_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ’¾ ì›¹ ìŠ¤í¬ë˜í•‘ ë°ì´í„° ì €ì¥:")
        print(f"   íŒŒì¼: {web_output_file}")
        print(f"   í¬ê¸°: {web_output_file.stat().st_size:,} bytes")
        
        await web_collector.close()
        
        return web_qa_pairs
        
    except Exception as e:
        print(f"âŒ ì›¹ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return []

def compare_collection_methods():
    """API ë°©ì‹ê³¼ ì›¹ ìŠ¤í¬ë˜í•‘ ë°©ì‹ ë¹„êµ"""
    print(f"\nğŸ“Š ìˆ˜ì§‘ ë°©ì‹ ë¹„êµ ë¶„ì„:")
    print("=" * 50)
    
    try:
        # API ë°©ì‹ ìµœì‹  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        api_files = list(Path(Config.OUTPUT_DIR).glob("large_scale_stackoverflow_*.json"))
        if api_files:
            latest_api_file = max(api_files, key=lambda f: f.stat().st_mtime)
            
            with open(latest_api_file, 'r', encoding='utf-8') as f:
                api_data = json.load(f)
            
            print(f"ğŸ“¡ API ë°©ì‹ ê²°ê³¼ (íŒŒì¼: {latest_api_file.name}):")
            print(f"   ìˆ˜ì§‘ ê°œìˆ˜: {len(api_data)}ê°œ")
            print(f"   íŒŒì¼ í¬ê¸°: {latest_api_file.stat().st_size:,} bytes")
            
            api_complete = sum(1 for item in api_data if item.get('answer'))
            print(f"   ì™„ì „í•œ Q&A: {api_complete}/{len(api_data)} ({api_complete/len(api_data)*100:.1f}%)")
        else:
            print("ğŸ“¡ API ë°©ì‹ ê²°ê³¼: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        # ì›¹ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        web_files = list(Path(Config.OUTPUT_DIR).glob("web_scraping_stackoverflow_*.json"))
        if web_files:
            latest_web_file = max(web_files, key=lambda f: f.stat().st_mtime)
            
            with open(latest_web_file, 'r', encoding='utf-8') as f:
                web_data = json.load(f)
            
            print(f"\nğŸŒ ì›¹ ìŠ¤í¬ë˜í•‘ ë°©ì‹ ê²°ê³¼ (íŒŒì¼: {latest_web_file.name}):")
            print(f"   ìˆ˜ì§‘ ê°œìˆ˜: {len(web_data)}ê°œ")
            print(f"   íŒŒì¼ í¬ê¸°: {latest_web_file.stat().st_size:,} bytes")
            
            web_complete = sum(1 for item in web_data if item.get('answer'))
            print(f"   ì™„ì „í•œ Q&A: {web_complete}/{len(web_data)} ({web_complete/len(web_data)*100:.1f}%)")
        else:
            print("\nğŸŒ ì›¹ ìŠ¤í¬ë˜í•‘ ë°©ì‹ ê²°ê³¼: ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•ŠìŒ")
        
        print(f"\nğŸ” ë¹„êµ ë¶„ì„:")
        print(f"   API ë°©ì‹ ì¥ì : ë¹ ë¦„, ì•ˆì •ì , êµ¬ì¡°í™”ëœ ë°ì´í„°")
        print(f"   API ë°©ì‹ ë‹¨ì : ì œí•œëœ í˜ì´ì§€, í• ë‹¹ëŸ‰ ì œí•œ")
        print(f"   ì›¹ ìŠ¤í¬ë˜í•‘ ì¥ì : ë¬´ì œí•œ í˜ì´ì§€, ë” ë§ì€ ë°ì´í„°")
        print(f"   ì›¹ ìŠ¤í¬ë˜í•‘ ë‹¨ì : ëŠë¦¼, ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ")
        
    except Exception as e:
        print(f"ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Stack Overflow ì›¹ ìŠ¤í¬ë˜í•‘ vs API ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì›¹ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
    web_results = await test_web_scraping_collector()
    
    # ìˆ˜ì§‘ ë°©ì‹ ë¹„êµ
    compare_collection_methods()
    
    print(f"\nğŸ¯ ì›¹ ìŠ¤í¬ë˜í•‘ íŠ¹ì§•:")
    print(f"   âœ… s-pagination í´ë˜ìŠ¤ ê¸°ë°˜ í˜ì´ì§€ ìˆœíšŒ")
    print(f"   âœ… ê°œë³„ ì§ˆë¬¸ í˜ì´ì§€ ìƒì„¸ ìŠ¤í¬ë˜í•‘")
    print(f"   âœ… ì±„íƒëœ ë‹µë³€ ìš°ì„  ìˆ˜ì§‘")
    print(f"   âœ… API ì œí•œ ì—†ì´ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥")
    
    if web_results:
        print(f"   ğŸ‰ ì›¹ ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {len(web_results)}ê°œ Q&A ìˆ˜ì§‘")
    else:
        print(f"   âš ï¸ ì›¹ ìŠ¤í¬ë˜í•‘ ê°œì„  í•„ìš”")
    
    print(f"\nğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(main())