#!/usr/bin/env python3
"""
Stack Overflow ìˆ˜ì§‘ê¸° í†µí•© í…ŒìŠ¤íŠ¸
- ì˜¤ë¹ ë‘ë‚˜, ë ˆë”§ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‹¤ì œ ìš´ì˜ í…ŒìŠ¤íŠ¸
- ì¤‘ë³µ ê²€ì¶œ ì´ˆê¸°í™”
- 10ê°œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
"""
import asyncio
import json
import sqlite3
import sys
from pathlib import Path
from datetime import datetime, timedelta

sys.path.insert(0, str(Path(__file__).parent))

from config import Config
from core.cache import LocalCache, APICache
from collectors.fixed_stackoverflow_collector import FixedStackOverflowCollector

def clear_stackoverflow_deduplication():
    """Stack Overflow ì¤‘ë³µ ê²€ì¶œ ë°ì´í„° ì´ˆê¸°í™”"""
    print("ğŸ—‘ï¸ Stack Overflow ì¤‘ë³µ ê²€ì¶œ ì´ˆê¸°í™”")
    
    try:
        # ì¤‘ë³µ ì¶”ì ê¸° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        dedup_db_path = Path("/Users/kevin/bigdata/data/deduplication_tracker.db")
        
        if dedup_db_path.exists():
            with sqlite3.connect(dedup_db_path) as conn:
                # Stack Overflow ê´€ë ¨ ì¤‘ë³µ ë°ì´í„° ì‚­ì œ
                cursor = conn.execute("DELETE FROM stackoverflow_questions")
                deleted_count = cursor.rowcount
                conn.commit()
                print(f"   ì‚­ì œëœ Stack Overflow ì¤‘ë³µ í•­ëª©: {deleted_count}ê°œ")
        else:
            print("   ì¤‘ë³µ ì¶”ì ê¸° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
        
        # ìºì‹œë„ ì´ˆê¸°í™”
        with sqlite3.connect(Config.DATABASE_PATH) as conn:
            cursor = conn.execute("DELETE FROM cache WHERE key LIKE 'so_api:%' OR key LIKE 'fixed_%'")
            deleted_cache = cursor.rowcount
            conn.commit()
            print(f"   ì‚­ì œëœ ìºì‹œ í•­ëª©: {deleted_cache}ê°œ")
        
        print("âœ… Stack Overflow ì¤‘ë³µ ê²€ì¶œ ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ì¤‘ë³µ ê²€ì¶œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

async def test_stackoverflow_production_collection():
    """Stack Overflow ì‹¤ì œ ìš´ì˜ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
    print("\nğŸš€ Stack Overflow ì‹¤ì œ ìš´ì˜ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        # ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” (ì˜¤ë¹ ë‘ë‚˜/ë ˆë”§ê³¼ ë™ì¼í•œ ë°©ì‹)
        local_cache = LocalCache(Config.DATABASE_PATH)
        api_cache = APICache(local_cache)
        collector = FixedStackOverflowCollector(api_cache)
        
        print("âœ… Stack Overflow ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸ¯ ëª©í‘œ: 10ê°œ ê³ í’ˆì§ˆ Q&A ìˆ˜ì§‘")
        
        # ìµœê·¼ 1ê°œì›” ë°ì´í„°ë¡œ ì œí•œ (ë” ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
        from_date = datetime.now() - timedelta(days=30)
        print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {from_date.strftime('%Y-%m-%d')} ~ í˜„ì¬")
        
        print("\nğŸ”„ ìˆ˜ì§‘ ì‹œì‘...")
        start_time = datetime.now()
        
        # í˜ì´ì§€ë³„ë¡œ ìˆ˜ì§‘í•˜ì—¬ 10ê°œ ë‹¬ì„±í•  ë•Œê¹Œì§€ ê³„ì†
        collected_qa_pairs = []
        page = 1
        max_pages = 5  # ìµœëŒ€ 5í˜ì´ì§€ê¹Œì§€ ì‹œë„
        target_count = 10
        
        while len(collected_qa_pairs) < target_count and page <= max_pages:
            print(f"\nğŸ“„ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")
            
            # í•œ í˜ì´ì§€ì”© ìˆ˜ì§‘
            page_results = await collector.collect_excel_questions_fixed(
                from_date=from_date,
                max_pages=1  # í˜ì´ì§€ë³„ë¡œ ìˆ˜ì§‘
            )
            
            print(f"   í˜ì´ì§€ {page} ê²°ê³¼: {len(page_results)}ê°œ Q&A")
            
            if page_results:
                collected_qa_pairs.extend(page_results)
                print(f"   ëˆ„ì  ìˆ˜ì§‘: {len(collected_qa_pairs)}ê°œ")
            else:
                print("   ì´ í˜ì´ì§€ì—ì„œ ìƒˆë¡œìš´ ë°ì´í„° ì—†ìŒ")
                break
            
            page += 1
            
            # ëª©í‘œ ë‹¬ì„± ì‹œ ì¤‘ë‹¨
            if len(collected_qa_pairs) >= target_count:
                print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±! {len(collected_qa_pairs)}ê°œ ìˆ˜ì§‘")
                break
            
            # í˜ì´ì§€ ê°„ ì§€ì—° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            await asyncio.sleep(1)
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\nâ±ï¸ ìˆ˜ì§‘ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ)")
        print(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: {len(collected_qa_pairs)}ê°œ Q&A ìŒ")
        
        if collected_qa_pairs:
            # ìƒì„¸ ë¶„ì„ (ì˜¤ë¹ ë‘ë‚˜/ë ˆë”§ê³¼ ë™ì¼í•œ ë°©ì‹)
            print(f"\nğŸ” ìˆ˜ì§‘ ë°ì´í„° ë¶„ì„:")
            
            # ì™„ì„±ë„ ì²´í¬
            complete_pairs = sum(1 for pair in collected_qa_pairs if pair.get('answer'))
            print(f"   ì™„ì „í•œ Q&A ìŒ: {complete_pairs}/{len(collected_qa_pairs)} ({complete_pairs/len(collected_qa_pairs)*100:.1f}%)")
            
            # í’ˆì§ˆ ë¶„ì„
            quality_scores = [pair.get('quality_score', 0) for pair in collected_qa_pairs]
            question_scores = [pair['question'].get('score', 0) for pair in collected_qa_pairs]
            answer_scores = [pair['answer'].get('score', 0) for pair in collected_qa_pairs if pair.get('answer')]
            
            print(f"   í’ˆì§ˆ ì ìˆ˜: {min(quality_scores)} ~ {max(quality_scores)} (í‰ê· : {sum(quality_scores)/len(quality_scores):.1f})")
            print(f"   ì§ˆë¬¸ ì ìˆ˜: {min(question_scores)} ~ {max(question_scores)} (í‰ê· : {sum(question_scores)/len(question_scores):.1f})")
            if answer_scores:
                print(f"   ë‹µë³€ ì ìˆ˜: {min(answer_scores)} ~ {max(answer_scores)} (í‰ê· : {sum(answer_scores)/len(answer_scores):.1f})")
            
            # íƒœê·¸ ë¶„ì„
            all_tags = []
            for pair in collected_qa_pairs:
                all_tags.extend(pair['question'].get('tags', []))
            
            tag_counts = {}
            for tag in all_tags:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
            
            print(f"\nğŸ·ï¸ íƒœê·¸ ë¶„í¬:")
            for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"   {tag}: {count}íšŒ")
            
            # Excel í‚¤ì›Œë“œ ë¶„ì„
            excel_keywords = ['formula', 'function', 'vlookup', 'index', 'match', 'if', 'sum']
            keyword_counts = {kw: 0 for kw in excel_keywords}
            
            for pair in collected_qa_pairs:
                full_text = (
                    pair['question'].get('title', '') + ' ' + 
                    pair['question'].get('body_markdown', '') + ' ' + 
                    pair.get('answer', {}).get('body_markdown', '')
                ).lower()
                
                for keyword in excel_keywords:
                    if keyword in full_text:
                        keyword_counts[keyword] += 1
            
            print(f"\nğŸ”§ Excel í‚¤ì›Œë“œ ì–¸ê¸‰:")
            for kw, count in sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True):
                if count > 0:
                    print(f"   {kw}: {count}íšŒ")
            
            # ìƒ˜í”Œ ì¶œë ¥
            print(f"\nğŸ“ ìˆ˜ì§‘ëœ Q&A ìƒ˜í”Œ:")
            for i, pair in enumerate(collected_qa_pairs[:3], 1):
                question = pair['question']
                answer = pair.get('answer', {})
                
                print(f"\n   ìƒ˜í”Œ {i}:")
                print(f"   ğŸ“‹ ID: {question.get('question_id')}")
                print(f"   ğŸ“‹ ì œëª©: {question.get('title', 'N/A')[:80]}...")
                print(f"   ğŸ“‹ ì ìˆ˜: Q{question.get('score', 0)}/A{answer.get('score', 0)}")
                print(f"   ğŸ“‹ íƒœê·¸: {', '.join(question.get('tags', []))}")
                print(f"   ğŸ’¬ ë‹µë³€ ê¸¸ì´: {len(answer.get('body_markdown', ''))}ì")
            
            # ë°ì´í„° ì €ì¥ (ì˜¤ë¹ ë‘ë‚˜/ë ˆë”§ê³¼ ë™ì¼í•œ í˜•ì‹)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = Path(Config.OUTPUT_DIR) / f"stackoverflow_production_test_{timestamp}.json"
            
            # ì €ì¥ìš© ë°ì´í„° ë³€í™˜
            save_data = {
                'metadata': {
                    'source': 'stackoverflow',
                    'collection_method': 'api_production_test',
                    'collected_at': datetime.now().isoformat(),
                    'total_count': len(collected_qa_pairs),
                    'complete_pairs': complete_pairs,
                    'collection_duration_seconds': duration.total_seconds(),
                    'target_achieved': len(collected_qa_pairs) >= target_count
                },
                'qa_pairs': []
            }
            
            for pair in collected_qa_pairs:
                save_item = {
                    'question': pair['question'],
                    'answer': pair.get('answer'),
                    'quality_score': pair.get('quality_score', 0),
                    'source': 'stackoverflow_api',
                    'collected_at': pair.get('collected_at', datetime.now().isoformat())
                }
                save_data['qa_pairs'].append(save_item)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nğŸ’¾ ìˆ˜ì§‘ ë°ì´í„° ì €ì¥:")
            print(f"   íŒŒì¼: {output_file}")
            print(f"   í¬ê¸°: {output_file.stat().st_size:,} bytes")
            
            # API ì‚¬ìš©ëŸ‰ ì²´í¬
            stats = collector.get_collection_stats()
            print(f"\nğŸ“Š API ì‚¬ìš© í†µê³„:")
            print(f"   ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰: {stats['requests_today']}")
            print(f"   ë‚¨ì€ í• ë‹¹ëŸ‰: {stats['daily_quota_remaining']}")
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            success = len(collected_qa_pairs) >= target_count and complete_pairs == len(collected_qa_pairs)
            
            if success:
                print(f"\nğŸ‰ Stack Overflow ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                print(f"   âœ… ëª©í‘œ ë‹¬ì„±: {len(collected_qa_pairs)}/{target_count}ê°œ")
                print(f"   âœ… 100% ì™„ì„±ë„: ëª¨ë“  Q&Aì— ë‹µë³€ í¬í•¨")
                print(f"   âœ… ê³ í’ˆì§ˆ Excel ê´€ë ¨ ë°ì´í„°")
            else:
                print(f"\nâš ï¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ë¶€ë¶„ ì„±ê³µ")
                print(f"   ğŸ“Š ìˆ˜ì§‘ëŸ‰: {len(collected_qa_pairs)}/{target_count}ê°œ")
                print(f"   ğŸ“Š ì™„ì„±ë„: {complete_pairs}/{len(collected_qa_pairs)}ê°œ")
        
        else:
            print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        await collector.close()
        
        return collected_qa_pairs
        
    except Exception as e:
        print(f"âŒ Stack Overflow ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return []

def compare_with_other_collectors():
    """ë‹¤ë¥¸ ìˆ˜ì§‘ê¸°ë“¤ê³¼ ë¹„êµ"""
    print(f"\nğŸ“Š ë‹¤ë¥¸ ìˆ˜ì§‘ê¸°ì™€ ë¹„êµ ë¶„ì„")
    print("=" * 50)
    
    try:
        output_dir = Path(Config.OUTPUT_DIR)
        
        # ìˆ˜ì§‘ê¸°ë³„ ìµœì‹  íŒŒì¼ ì°¾ê¸°
        collectors = {
            'stackoverflow': list(output_dir.glob("stackoverflow_production_test_*.json")),
            'oppadu': list(output_dir.glob("*oppadu*.json")),
            'reddit': list(output_dir.glob("*reddit*.json"))
        }
        
        comparison_data = {}
        
        for collector_name, files in collectors.items():
            if files:
                latest_file = max(files, key=lambda f: f.stat().st_mtime)
                
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    if collector_name == 'stackoverflow':
                        qa_count = len(data.get('qa_pairs', []))
                        complete_count = sum(1 for item in data.get('qa_pairs', []) if item.get('answer'))
                    else:
                        qa_count = len(data) if isinstance(data, list) else len(data.get('items', []))
                        complete_count = qa_count  # ë‹¤ë¥¸ ìˆ˜ì§‘ê¸°ë“¤ì€ ì™„ì„±ë„ ê°€ì •
                    
                    comparison_data[collector_name] = {
                        'file': latest_file.name,
                        'count': qa_count,
                        'complete': complete_count,
                        'size': latest_file.stat().st_size
                    }
                    
                except Exception as e:
                    print(f"   {collector_name} íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            else:
                comparison_data[collector_name] = None
        
        print("ğŸ“ˆ ìˆ˜ì§‘ê¸°ë³„ ì„±ëŠ¥ ë¹„êµ:")
        for collector_name, data in comparison_data.items():
            if data:
                print(f"\n   {collector_name.upper()}:")
                print(f"   ğŸ“„ íŒŒì¼: {data['file']}")
                print(f"   ğŸ“Š ìˆ˜ì§‘ëŸ‰: {data['count']}ê°œ")
                print(f"   âœ… ì™„ì„±ë„: {data['complete']}/{data['count']} ({data['complete']/data['count']*100:.1f}%)")
                print(f"   ğŸ’¾ í¬ê¸°: {data['size']:,} bytes")
            else:
                print(f"\n   {collector_name.upper()}: ë°ì´í„° ì—†ìŒ")
        
    except Exception as e:
        print(f"ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Stack Overflow ìˆ˜ì§‘ê¸° í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print("ğŸ“ ì˜¤ë¹ ë‘ë‚˜, ë ˆë”§ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‹¤ì œ ìš´ì˜ í…ŒìŠ¤íŠ¸")
    
    # 1. ì¤‘ë³µ ê²€ì¶œ ì´ˆê¸°í™”
    clear_stackoverflow_deduplication()
    
    # 2. ì‹¤ì œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (10ê°œ ëª©í‘œ)
    results = await test_stackoverflow_production_collection()
    
    # 3. ë‹¤ë¥¸ ìˆ˜ì§‘ê¸°ì™€ ë¹„êµ
    compare_with_other_collectors()
    
    # 4. ìµœì¢… ê²°ê³¼
    print(f"\nğŸ Stack Overflow í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    if results and len(results) >= 10:
        print(f"   ğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(results)}ê°œ Q&A ìˆ˜ì§‘")
        print(f"   âœ… ì˜¤ë¹ ë‘ë‚˜/ë ˆë”§ê³¼ ë™ì¼í•œ ìˆ˜ì¤€ì˜ ì•ˆì •ì„±")
        print(f"   ğŸ“Š Stack Overflow ìˆ˜ì§‘ê¸° ìš´ì˜ ì¤€ë¹„ ì™„ë£Œ")
    elif results:
        print(f"   âš ï¸ ë¶€ë¶„ ì„±ê³µ: {len(results)}ê°œ Q&A ìˆ˜ì§‘")
        print(f"   ğŸ”„ ë” ë§ì€ ë°ì´í„° í™•ë³´ë¥¼ ìœ„í•´ ìˆ˜ì§‘ ë²”ìœ„ í™•ì¥ í•„ìš”")
    else:
        print(f"   âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ë°ì´í„° ìˆ˜ì§‘ ì•ˆë¨")
        print(f"   ğŸ”§ ìˆ˜ì§‘ ë¡œì§ ì ê²€ í•„ìš”")

if __name__ == "__main__":
    asyncio.run(main())