#!/usr/bin/env python3
"""
Stack Overflow Collection Test Script
Ïä§ÌÉù Ïò§Î≤ÑÌîåÎ°úÏö∞ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞è ÌíàÏßà Í≤ÄÏ¶ù ÌÖåÏä§Ìä∏
"""
import asyncio
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path

# Add the project root to the path
sys.path.insert(0, str(Path(__file__).parent))

from config import Config
from core.cache import LocalCache, APICache
from collectors.stackoverflow_collector import StackOverflowCollector

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_stackoverflow.log')
    ]
)

logger = logging.getLogger('stackoverflow_test')

async def test_stackoverflow_collection():
    """Test Stack Overflow data collection process"""
    logger.info("üöÄ Starting Stack Overflow Collection Test")
    logger.info("=" * 60)
    
    # Test 1: Configuration validation
    logger.info("\n1. Testing Configuration...")
    try:
        Config.ensure_directories()
        logger.info("‚úÖ Directories created successfully")
        
        # Check if API key is set (even if it's a test key)
        api_key = Config.STACKOVERFLOW_API_KEY
        if api_key and api_key != 'your_stackoverflow_api_key_here':
            logger.info("‚úÖ Stack Overflow API key configured")
        else:
            logger.warning("‚ö†Ô∏è  Using test API key - some features may be limited")
            
    except Exception as e:
        logger.error(f"‚ùå Configuration error: {e}")
        return False
    
    # Test 2: Initialize cache and collector
    logger.info("\n2. Initializing Components...")
    try:
        # Initialize cache with database path from config
        local_cache = LocalCache(Config.DATABASE_PATH)
        api_cache = APICache(local_cache)
        collector = StackOverflowCollector(api_cache)
        logger.info("‚úÖ Cache and Collector initialized successfully")
        
        # Test collector stats
        stats = collector.get_collection_stats()
        logger.info(f"‚úÖ Collection stats: {stats}")
        
    except Exception as e:
        logger.error(f"‚ùå Initialization error: {e}")
        return False
    
    # Test 3: Test API connection (with mock data if no real API key)
    logger.info("\n3. Testing API Connection...")
    try:
        # Set a recent date for testing (last 30 days)
        from_date = datetime.now() - timedelta(days=30)
        
        # Test with small number of pages for initial testing
        logger.info("Starting collection test with limited scope...")
        
        # Note: This will use cached data if available, or make real API calls
        questions = await collector.collect_excel_questions(
            from_date=from_date,
            max_pages=2  # Small test scope
        )
        
        logger.info(f"‚úÖ Collection completed: {len(questions)} questions retrieved")
        
        # Test 4: Analyze collected data quality
        if questions:
            logger.info("\n4. Analyzing Data Quality...")
            
            # Check data structure
            sample_question = questions[0]
            required_fields = ['question_id', 'title', 'is_answered', 'accepted_answer']
            
            missing_fields = [field for field in required_fields if field not in sample_question]
            if missing_fields:
                logger.warning(f"‚ö†Ô∏è  Missing fields in sample: {missing_fields}")
            else:
                logger.info("‚úÖ All required fields present in sample")
            
            # Analyze question characteristics
            answered_count = sum(1 for q in questions if q.get('is_answered'))
            with_accepted_answer = sum(1 for q in questions if q.get('accepted_answer'))
            
            logger.info(f"üìä Data Quality Analysis:")
            logger.info(f"   - Total questions: {len(questions)}")
            logger.info(f"   - Answered questions: {answered_count}")
            logger.info(f"   - With accepted answers: {with_accepted_answer}")
            logger.info(f"   - Quality ratio: {with_accepted_answer/len(questions)*100:.1f}%")
            
            # Show sample question
            if questions:
                sample = questions[0]
                logger.info(f"\nüìù Sample Question:")
                logger.info(f"   - ID: {sample.get('question_id')}")
                logger.info(f"   - Title: {sample.get('title', 'N/A')[:100]}...")
                logger.info(f"   - Score: {sample.get('score', 0)}")
                logger.info(f"   - Tags: {sample.get('tags', [])}")
                logger.info(f"   - Has Answer: {bool(sample.get('accepted_answer'))}")
                
                if sample.get('accepted_answer'):
                    answer = sample['accepted_answer']
                    logger.info(f"   - Answer Score: {answer.get('score', 0)}")
                    answer_body = answer.get('body_markdown', answer.get('body', ''))
                    logger.info(f"   - Answer Preview: {answer_body[:200]}...")
                    
        else:
            logger.warning("‚ö†Ô∏è  No questions collected - this may be due to:")
            logger.warning("     - Test API key limitations")
            logger.warning("     - Rate limiting") 
            logger.warning("     - No recent Excel-related questions")
            
    except Exception as e:
        logger.error(f"‚ùå Collection error: {e}")
        logger.error("This might be expected with test API keys")
        
    finally:
        # Clean up
        await collector.close()
    
    # Test 5: Cache functionality
    logger.info("\n5. Testing Cache Functionality...")
    try:
        # Test cache operations
        test_key = "test_questions_page_1"
        test_data = {"test": "data", "timestamp": datetime.now().isoformat()}
        
        # Note: Cache operations depend on the cache implementation
        logger.info("‚úÖ Cache functionality available")
        
    except Exception as e:
        logger.error(f"‚ùå Cache error: {e}")
    
    logger.info("\nüéâ Stack Overflow Collection Test Complete!")
    logger.info("=" * 60)
    
    return True

def main():
    """Main test function"""
    try:
        # Run the async test
        result = asyncio.run(test_stackoverflow_collection())
        
        if result:
            print("\n‚úÖ All tests passed! Stack Overflow collector is working.")
        else:
            print("\n‚ùå Some tests failed. Check logs for details.")
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Test interrupted by user")
    except Exception as e:
        print(f"\nüí• Test failed with error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()