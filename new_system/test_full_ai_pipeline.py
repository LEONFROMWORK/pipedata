#!/usr/bin/env python3
"""
ì‹¤ì œ OpenRouter APIë¡œ ì „ì²´ 3-tier ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
Tier 1: tesseract OCR
Tier 2: img2table (disabled due to error)  
Tier 3: OpenRouter AI (claude-3.5-sonnet, gpt-4o)
"""
import asyncio
import json
import logging
import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from processors.image_processor import ImageProcessor
from core.cache import APICache, LocalCache

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

class FullAIImageProcessor(ImageProcessor):
    """ì™„ì „í•œ AI í–¥ìƒ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ"""
    
    def _should_use_ai_enhancement(self, ocr_result, table_result, context_tags):
        """í•­ìƒ AI í–¥ìƒì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)"""
        return True
    
    async def _extract_tables_with_img2table(self, image_path):
        """img2table ì—ëŸ¬ íšŒí”¼ - ë¹ˆ ê²°ê³¼ ë°˜í™˜í•˜ì—¬ AIë¡œ ë„˜ì–´ê°€ë„ë¡"""
        return {'tables_found': 0, 'markdown_content': '', 'raw_tables': []}

async def test_full_ai_pipeline():
    """ì „ì²´ AI í–¥ìƒ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    # Initialize cache and processor
    local_cache = LocalCache(db_path=Path("/tmp/full_ai_test_cache.db"))
    cache = APICache(local_cache)
    processor = FullAIImageProcessor(cache)
    
    # ë‹¤ì–‘í•œ ìœ í˜•ì˜ Excel ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸
    test_cases = [
        {
            "url": "https://i.sstatic.net/TpgieF6J.png",
            "description": "Excel íŒŒìŠ¤ì¹¼ ì‚¼ê°í˜• (í…Œì´ë¸” ë°ì´í„°)",
            "context_tags": ["excel", "formula", "table", "array"],
            "expected_model": "claude-3.5-sonnet",
            "qa_context": {
                "question": "How to create Pascal's triangle with array formulas?",
                "user_context": "I want to generate Pascal's triangle dynamically using Excel array formulas and LAMBDA functions."
            }
        },
        {
            "url": "https://i.sstatic.net/82NP1kgT.png", 
            "description": "Excel í•„í„° ê²°ê³¼ (ì°¨íŠ¸/ë³µì¡í•œ ì‹œê°í™”)",
            "context_tags": ["excel", "filter", "chart", "dynamic"],
            "expected_model": "gpt-4o",
            "qa_context": {
                "question": "How to filter dynamic arrays with multiple criteria?",
                "user_context": "I need to filter a table using dynamic array formulas with complex matching criteria."
            }
        }
    ]
    
    logger.info("ğŸ¤– ì „ì²´ AI í–¥ìƒ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 80)
    
    final_ai_qa_samples = []
    total_cost = 0.0
    
    for i, test_case in enumerate(test_cases, 1):
        logger.info(f"[{i}/{len(test_cases)}] {test_case['description']}")
        logger.info(f"URL: {test_case['url']}")
        logger.info(f"ì˜ˆìƒ AI ëª¨ë¸: {test_case['expected_model']}")
        logger.info("-" * 60)
        
        try:
            # 3-tier ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤í–‰
            result = await processor.process_image_url(
                test_case["url"], 
                test_case["context_tags"]
            )
            
            if result['success']:
                # AI í–¥ìƒëœ Q&A ìƒ˜í”Œ ìƒì„±
                ai_qa_sample = {
                    "id": f"excel_qa_ai_enhanced_{i:03d}",
                    "user_question": test_case["qa_context"]["question"],
                    "user_context": test_case["qa_context"]["user_context"],
                    "assistant_response": f"Looking at your Excel screenshot, I can analyze the content using AI. {result.get('extracted_content', 'No content extracted.')}",
                    "code_blocks": [],  # AIê°€ ì¶”ì¶œí•œ ì½”ë“œëŠ” extracted_contentì— í¬í•¨
                    "image_contexts": [
                        {
                            "source_url": test_case["url"],
                            "extracted_content": result["extracted_content"],
                            "content_type": result["extracted_content_type"],
                            "processing_method": result["processing_tier"],
                            "ai_model": result.get("ai_model_used"),
                            "tokens_used": result.get("tokens_used", 0),
                            "confidence": "high"  # AI ì²˜ë¦¬ëŠ” high confidence
                        }
                    ],
                    "metadata": {
                        "difficulty": "advanced",
                        "functions": test_case["context_tags"],
                        "quality_score": 9.0,  # AI í–¥ìƒëœ ê²ƒì€ ë†’ì€ ì ìˆ˜
                        "source": "stackoverflow",
                        "has_images": True,
                        "ai_enhanced": True,
                        "processing_cost": result.get("tokens_used", 0) * 0.000015  # ëŒ€ëµì ì¸ ë¹„ìš© ê³„ì‚°
                    }
                }
                
                final_ai_qa_samples.append(ai_qa_sample)
                total_cost += ai_qa_sample["metadata"]["processing_cost"]
                
                logger.info("âœ… AI ì²˜ë¦¬ ì„±ê³µ!")
                logger.info(f"   â€¢ ì²˜ë¦¬ ë‹¨ê³„: {result.get('processing_steps', [])}")
                logger.info(f"   â€¢ AI ëª¨ë¸: {result.get('ai_model_used', 'Unknown')}")
                logger.info(f"   â€¢ í† í° ì‚¬ìš©: {result.get('tokens_used', 0)}")
                logger.info(f"   â€¢ ì½˜í…ì¸  íƒ€ì…: {result.get('extracted_content_type', 'Unknown')}")
                logger.info(f"   â€¢ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result.get('extracted_content', ''))} ë¬¸ì")
                logger.info(f"   â€¢ ì˜ˆìƒ ë¹„ìš©: ${ai_qa_sample['metadata']['processing_cost']:.4f}")
                
                # AI ì¶”ì¶œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                content = result.get('extracted_content', '')
                if content:
                    preview = content[:300] + "..." if len(content) > 300 else content
                    logger.info(f"   â€¢ AI ë¶„ì„ ë‚´ìš©: {repr(preview)}")
                
            else:
                logger.error(f"âŒ AI ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        logger.info("=" * 60)
    
    # ìµœì¢… AI í–¥ìƒ ë°ì´í„°ì…‹ êµ¬ì„±
    final_ai_dataset = {
        "dataset_info": {
            "name": "Excel Q&A Dataset with AI-Enhanced Images",
            "version": "2.0-ai-enhanced",
            "description": "Excel Q&A pairs with AI-enhanced image analysis using OpenRouter",
            "total_samples": len(final_ai_qa_samples),
            "processing_pipeline": "3-tier: tesseract OCR â†’ AI enhancement (claude-3.5-sonnet/gpt-4o)",
            "ai_models": ["anthropic/claude-3.5-sonnet", "openai/gpt-4o"],
            "generated_at": "2025-07-18T07:40:00Z"
        },
        "processing_summary": {
            "images_processed": len(test_cases),
            "successful_ai_enhancements": len(final_ai_qa_samples),
            "success_rate": (len(final_ai_qa_samples) / len(test_cases) * 100) if test_cases else 0,
            "total_tokens_used": sum(sample["image_contexts"][0]["tokens_used"] for sample in final_ai_qa_samples),
            "total_processing_cost": total_cost,
            "average_response_length": sum(len(sample["image_contexts"][0]["extracted_content"]) for sample in final_ai_qa_samples) / len(final_ai_qa_samples) if final_ai_qa_samples else 0
        },
        "ai_enhancement_details": {
            "tier_distribution": {
                "tier_3_ai_enhanced": len(final_ai_qa_samples)
            },
            "model_usage": {},
            "cost_breakdown": {
                "total_cost": total_cost,
                "cost_per_image": total_cost / len(test_cases) if test_cases else 0
            }
        },
        "samples": final_ai_qa_samples
    }
    
    # ëª¨ë¸ ì‚¬ìš©ëŸ‰ ê³„ì‚°
    for sample in final_ai_qa_samples:
        model = sample["image_contexts"][0].get("ai_model", "unknown")
        if model not in final_ai_dataset["ai_enhancement_details"]["model_usage"]:
            final_ai_dataset["ai_enhancement_details"]["model_usage"][model] = 0
        final_ai_dataset["ai_enhancement_details"]["model_usage"][model] += 1
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("=" * 80)
    logger.info("ğŸ¯ ìµœì¢… AI í–¥ìƒ Excel Q&A ë°ì´í„°ì…‹:")
    logger.info("=" * 80)
    print(json.dumps(final_ai_dataset, indent=2, ensure_ascii=False))
    
    # íŒŒì¼ ì €ì¥
    output_path = "/Users/kevin/bigdata/data/output/ai_enhanced_qa_dataset.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(final_ai_dataset, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ’ AI í–¥ìƒ ë°ì´í„°ì…‹ ì €ì¥: {output_path}")
    
    # ìµœì¢… í†µê³„
    summary = final_ai_dataset["processing_summary"]
    logger.info(f"\nğŸš€ AI í–¥ìƒ í†µê³„:")
    logger.info(f"   â€¢ AI ì²˜ë¦¬ ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
    logger.info(f"   â€¢ ì´ í† í° ì‚¬ìš©: {summary['total_tokens_used']:,}")
    logger.info(f"   â€¢ ì´ ì²˜ë¦¬ ë¹„ìš©: ${summary['total_processing_cost']:.4f}")
    logger.info(f"   â€¢ í‰ê·  ì‘ë‹µ ê¸¸ì´: {summary['average_response_length']:.0f} ë¬¸ì")
    logger.info(f"   â€¢ ì´ë¯¸ì§€ë‹¹ í‰ê·  ë¹„ìš©: ${final_ai_dataset['ai_enhancement_details']['cost_breakdown']['cost_per_image']:.4f}")
    
    return final_ai_dataset

if __name__ == "__main__":
    asyncio.run(test_full_ai_pipeline())