#!/usr/bin/env python3
"""
ê¸°ì¡´ JSON ë°ì´í„°ì…‹ì˜ í˜•ì‹ ë¬¸ì œ í•´ê²°
- HTML íƒœê·¸ ì œê±°
- Excel ê³µì‹ ì •í™•í•œ ì¶”ì¶œ
- ì¼ê´€ëœ í…ìŠ¤íŠ¸ í¬ë§· ì ìš©
"""
import json
import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from processors.text_cleaner import TextCleaner
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def fix_dataset_format(input_path: str, output_path: str) -> None:
    """ë°ì´í„°ì…‹ í˜•ì‹ ë¬¸ì œ ìˆ˜ì •"""
    
    cleaner = TextCleaner()
    
    logger.info(f"ğŸ“„ ë°ì´í„°ì…‹ ë¡œë“œ: {input_path}")
    
    # JSON íŒŒì¼ì´ JSONL í˜•ì‹ì¸ì§€ í™•ì¸
    is_jsonl = input_path.endswith('.jsonl')
    
    if is_jsonl:
        # JSONL íŒŒì¼ ì²˜ë¦¬
        samples = []
        with open(input_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    samples.append(json.loads(line))
    else:
        # ì¼ë°˜ JSON íŒŒì¼ ì²˜ë¦¬
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            samples = data.get('samples', [data])  # ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš°ë„ ì²˜ë¦¬
    
    logger.info(f"ğŸ”§ {len(samples)}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì‹œì‘")
    
    fixed_samples = []
    total_formulas = 0
    
    for i, sample in enumerate(samples, 1):
        if 'assistant_response' in sample:
            # ì›ë³¸ ì‘ë‹µ ì •ë¦¬
            original_response = sample['assistant_response']
            cleaned = cleaner.clean_qa_response(original_response)
            
            # ì—…ë°ì´íŠ¸ëœ ìƒ˜í”Œ ìƒì„±
            fixed_sample = sample.copy()
            fixed_sample['assistant_response'] = cleaned['clean_text']
            fixed_sample['code_blocks'] = cleaned['extracted_formulas']
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            if 'metadata' not in fixed_sample:
                fixed_sample['metadata'] = {}
            
            fixed_sample['metadata']['has_code'] = cleaned['has_code']
            fixed_sample['metadata']['formula_count'] = len(cleaned['extracted_formulas'])
            fixed_sample['metadata']['text_cleaned'] = True
            
            fixed_samples.append(fixed_sample)
            total_formulas += len(cleaned['extracted_formulas'])
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if i % 1 == 0:  # ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ì¶œë ¥ (ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ)
                logger.info(f"  [{i}/{len(samples)}] ì²˜ë¦¬ ì™„ë£Œ - ê³µì‹ {len(cleaned['extracted_formulas'])}ê°œ ì¶”ì¶œ")
        else:
            # assistant_responseê°€ ì—†ëŠ” ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€
            fixed_samples.append(sample)
    
    # ìˆ˜ì •ëœ ë°ì´í„°ì…‹ êµ¬ì„±
    if is_jsonl:
        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            for sample in fixed_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    else:
        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
        fixed_dataset = {
            "dataset_info": {
                "name": "Fixed Excel Q&A Dataset",
                "version": "2.0-cleaned",
                "description": "Excel Q&A dataset with cleaned HTML tags and extracted formulas",
                "total_samples": len(fixed_samples),
                "total_formulas_extracted": total_formulas,
                "processing_notes": [
                    "HTML tags removed from assistant responses",
                    "Excel formulas accurately extracted and normalized",
                    "Text formatting standardized"
                ],
                "generated_at": "2025-07-18T07:50:00Z"
            },
            "processing_summary": {
                "samples_processed": len(fixed_samples),
                "formulas_extracted": total_formulas,
                "average_formulas_per_sample": total_formulas / len(fixed_samples) if fixed_samples else 0
            },
            "samples": fixed_samples
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(fixed_dataset, f, indent=2, ensure_ascii=False)
    
    logger.info(f"âœ… ìˆ˜ì • ì™„ë£Œ!")
    logger.info(f"   â€¢ ì²˜ë¦¬ëœ ìƒ˜í”Œ: {len(fixed_samples)}ê°œ")
    logger.info(f"   â€¢ ì¶”ì¶œëœ ê³µì‹: {total_formulas}ê°œ")
    logger.info(f"   â€¢ ì €ì¥ ê²½ë¡œ: {output_path}")

def demonstrate_fixes():
    """ìˆ˜ì • ì „í›„ ë¹„êµ ì˜ˆì‹œ"""
    cleaner = TextCleaner()
    
    # ì‹¤ì œ ë¬¸ì œê°€ ìˆë˜ ì‘ë‹µë“¤
    problematic_responses = [
        "<p>Use MAXIFS()</p>\n<pre><code>=MAXIFS(B:B,A:A,&quot;Apples&quot;)\n</code></pre>\n<p>Make sure to format the output as a date.</p>",
        
        "<p>&quot;I was wondering if there is a way in Excel to have an array function that, for some cells in the array, references the values in other cells within the array&quot; - can be only possible with the REDUCE function in combination with the VSTACK or HSTACK function.</p>\n<p>The formula for Pascal's triangle is:</p>\n<pre><code>=LET(N,5,REDUCE(SEQUENCE(,N,1,0),SEQUENCE(N-1),\n    LAMBDA(y,z,VSTACK(y,SCAN(0,TAKE(y,-1),LAMBDA(a,x,a+x))))))\n</code></pre>",
        
        "<p><a href=\"https://i.sstatic.net/AJr6APk8.png\" rel=\"noreferrer\"><img src=\"https://i.sstatic.net/AJr6APk8.png\" alt=\"enter image description here\" /></a></p>\n<p>Formula in <code>E2</code>:</p>\n<p><code>=LET(_data,A2:C7,TEXTSPLIT(TEXTAFTER(UNIQUE(BYROW(DROP(REDUCE(0,SEQUENCE(ROWS(_data)),LAMBDA(_main,_iter,LET(_index,INDEX(_data,_iter,),_4th,BYROW(FILTER(_data,BYROW(_data,LAMBDA(_row,SUM(COUNTIF(_index,_row))=2))),LAMBDA(_row,FILTER(_row,COUNTIF(_index,_row)=0))),IF(@ISERR(_4th),_main,VSTACK(_main,IF({1,0,0,0},_4th,HSTACK(0,_index))))))),1),LAMBDA(_row,TEXTJOIN(0,0,,SORT(_row,,,1))))),0,{1,2,3,4}),0))</code></p>"
    ]
    
    print("ğŸ” ìˆ˜ì • ì „í›„ ë¹„êµ:")
    print("=" * 80)
    
    for i, response in enumerate(problematic_responses, 1):
        print(f"\n[ì˜ˆì‹œ {i}]")
        print("ğŸ”´ ìˆ˜ì • ì „:")
        print(f"  ê¸¸ì´: {len(response)} ë¬¸ì")
        print(f"  ë‚´ìš©: {repr(response[:100])}...")
        
        cleaned = cleaner.clean_qa_response(response)
        
        print("ğŸŸ¢ ìˆ˜ì • í›„:")
        print(f"  ê¸¸ì´: {len(cleaned['clean_text'])} ë¬¸ì")
        print(f"  ë‚´ìš©: {repr(cleaned['clean_text'][:100])}...")
        print(f"  ì¶”ì¶œëœ ê³µì‹: {len(cleaned['extracted_formulas'])}ê°œ")
        for j, formula in enumerate(cleaned['extracted_formulas'][:3], 1):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
            print(f"    {j}. {formula}")
        if len(cleaned['extracted_formulas']) > 3:
            print(f"    ... (+{len(cleaned['extracted_formulas'])-3}ê°œ ë”)")
        print("-" * 60)

if __name__ == "__main__":
    # ìˆ˜ì • ì˜ˆì‹œ ì‹œì—°
    demonstrate_fixes()
    
    print("\n" + "=" * 80)
    
    # ì‹¤ì œ ë°ì´í„°ì…‹ íŒŒì¼ë“¤ ìˆ˜ì •
    datasets_to_fix = [
        ("/Users/kevin/bigdata/data/output/year=2025/month=07/day=18/combined_20250718.jsonl", 
         "/Users/kevin/bigdata/data/output/cleaned_combined_20250718.jsonl"),
        
        ("/Users/kevin/bigdata/data/output/ai_enhanced_qa_dataset.json", 
         "/Users/kevin/bigdata/data/output/cleaned_ai_enhanced_qa_dataset.json"),
        
        ("/Users/kevin/bigdata/data/output/ocr_based_qa_dataset.json", 
         "/Users/kevin/bigdata/data/output/cleaned_ocr_based_qa_dataset.json")
    ]
    
    for input_path, output_path in datasets_to_fix:
        if Path(input_path).exists():
            try:
                fix_dataset_format(input_path, output_path)
            except Exception as e:
                logger.error(f"âŒ {input_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        else:
            logger.warning(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {input_path}")
    
    logger.info("\nğŸ‰ ëª¨ë“  ë°ì´í„°ì…‹ í˜•ì‹ ìˆ˜ì • ì™„ë£Œ!")